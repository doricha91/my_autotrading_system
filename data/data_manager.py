# data/data_manager.py
# ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°, ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰, ë°ì´í„° ë¡œë”©ì„ ì´ê´„í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
# ë‹¤ë¥¸ ëª¨ë“ˆë“¤ì€ ì´ íŒŒì¼ì„ í†µí•´ ë°ì´í„°ì— ì ‘ê·¼í•©ë‹ˆë‹¤.

import sqlite3
import pandas as pd
import numpy as np # numpy import ì¶”ê°€
import logging
from datetime import datetime
from utils import indicators # indicators ëª¨ë“ˆ import ì¶”ê°€
# ê°™ì€ data í´ë” ë‚´ì˜ collectors íŒ¨í‚¤ì§€ì—ì„œ ê° ëª¨ë“ˆì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from .collectors import ohlcv_collector, fng_collector, macro_collector, market_index_collector

logger = logging.getLogger()


def run_all_collectors(config):
    """
    ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ê¸°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ DBë¥¼ ìµœì‹  ìƒíƒœë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    ì´ í•¨ìˆ˜ëŠ” main.pyì—ì„œ 'collect' ëª¨ë“œë¡œ ì‹¤í–‰ ì‹œ í˜¸ì¶œë©ë‹ˆë‹¤.
    """
    logger.info("ğŸš€ ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    # 1. OHLCV ë°ì´í„° ìˆ˜ì§‘ ë° ì‹œì¥ ì§€ìˆ˜ ìƒì„±
    # ë‘ ì‘ì—… ëª¨ë‘ ë™ì¼í•œ DB íŒŒì¼ì„ ì‚¬ìš©í•˜ë¯€ë¡œ í•˜ë‚˜ì˜ connectionìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    try:
        with sqlite3.connect(config.OHLCV_DB_PATH) as con:
            # 1-1. OHLCV ë°ì´í„° ì—…ë°ì´íŠ¸
            for interval in config.OHLCV_INTERVALS_TO_COLLECT:
                logger.info(f"--- {interval} ê°„ê²© OHLCV ë°ì´í„° ì²˜ë¦¬ ì‹œì‘ ---")
                for ticker in config.TICKERS_TO_COLLECT_OHLCV:
                    ohlcv_collector.update_ohlcv_db(con, ticker, interval)
            logger.info("âœ… OHLCV ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ.")

            # 1-2. ì‹œì¥ ì§€ìˆ˜ ìƒì„±/ì—…ë°ì´íŠ¸
            logger.info("--- ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ìƒì„± ì‹œì‘ ---")
            market_index_series = market_index_collector.calculate_market_index(
                con=con,
                tickers=config.BLUE_CHIP_TICKERS_FOR_INDEX,
                interval="day",  # ì‹œì¥ ì§€ìˆ˜ëŠ” ë³´í†µ ì¼ë´‰ ê¸°ì¤€ìœ¼ë¡œ ìƒì„±
                start_date="2017-09-01",  # ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” ê°€ì¥ ì´ë¥¸ ì‹œì 
                end_date=datetime.today().strftime('%Y-%m-%d')
            )
            market_index_collector.save_to_sqlite(market_index_series, con, config.MARKET_INDEX_TABLE)

    except Exception as e:
        logger.error(f"âŒ OHLCV ë˜ëŠ” ì‹œì¥ ì§€ìˆ˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

    # 2. ê³µí¬íƒìš•ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘
    try:
        with sqlite3.connect(config.FNG_DB_PATH) as con:
            fng_df = fng_collector.fetch_all_fng_data()
            if not fng_df.empty:
                fng_collector.save_to_sqlite(fng_df, con, config.FNG_TABLE)
    except Exception as e:
        logger.error(f"âŒ ê³µí¬íƒìš•ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

    # 3. ê±°ì‹œê²½ì œì§€í‘œ ë°ì´í„° ìˆ˜ì§‘
    try:
        with sqlite3.connect(config.MACRO_DB_PATH) as con:
            start_date = "2017-01-01"
            end_date = datetime.today().strftime('%Y-%m-%d')
            macro_df = macro_collector.fetch_macro_data(start_date, end_date)
            if not macro_df.empty:
                macro_collector.save_to_sqlite(macro_df, con, config.MACRO_TABLE)
    except Exception as e:
        logger.error(f"âŒ ê±°ì‹œê²½ì œì§€í‘œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

    logger.info("ğŸ‰ ëª¨ë“  ë°ì´í„° ì¤€ë¹„ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


def load_prepared_data(config, ticker: str, interval: str, for_bot: bool = False) -> pd.DataFrame:
    """
    ìë™ë§¤ë§¤ ë´‡ ë˜ëŠ” ë°±í…ŒìŠ¤í„°ë¥¼ ìœ„í•´ í•„ìš”í•œ ëª¨ë“  ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ë³‘í•©í•©ë‹ˆë‹¤.
    (ê¸°ì¡´ autotrading.pyì™€ advanced_backtest.pyì˜ load_and_prepare_data í•¨ìˆ˜ë¥¼ í†µí•©)

    Args:
        ticker (str): ë°ì´í„°ë¥¼ ë¡œë“œí•  ë©”ì¸ í‹°ì»¤ (ì˜ˆ: "KRW-BTC")
        interval (str): ì‹œê°„ ê°„ê²© (ì˜ˆ: "day", "minute60")
        for_bot (bool): ë´‡ ì‹¤í–‰ìš©ì¸ì§€ ì—¬ë¶€. Trueì´ë©´ ìµœê·¼ 350ê°œ ë°ì´í„°ë§Œ ë¡œë“œ.

    Returns:
        pd.DataFrame: ëª¨ë“  ë°ì´í„°ê°€ ë³‘í•©ë˜ê³  ì „ì²˜ë¦¬ëœ ìµœì¢… ë°ì´í„°í”„ë ˆì„
    """
    logger.info(f"ë°ì´í„° ë¡œë”© ë° ë³‘í•© ì‹œì‘ (Ticker: {ticker}, Interval: {interval})")
    ohlcv_table = f"{ticker.replace('-', '_')}_{interval}"

    try:
        # 1. ê° DBì—ì„œ ë°ì´í„° ë¡œë“œ
        with sqlite3.connect(config.OHLCV_DB_PATH) as con:
            # ë´‡ ì‹¤í–‰ ì‹œì—ëŠ” ëª¨ë“  ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ í•„ìš” ì—†ì´ ìµœê·¼ ë°ì´í„°ë§Œ ì‚¬ìš©
            query = f'SELECT * FROM "{ohlcv_table}"'
            if for_bot:
                query += " ORDER BY timestamp DESC LIMIT 2000"
            df_ohlcv = pd.read_sql_query(query, con, index_col='timestamp', parse_dates=['timestamp'])

            # ë´‡ ì‹¤í–‰ ì‹œì—ëŠ” ì‹œê°„ ì—­ìˆœìœ¼ë¡œ ê°€ì ¸ì™”ìœ¼ë¯€ë¡œ ë‹¤ì‹œ ì •ìˆœìœ¼ë¡œ ì •ë ¬
            if for_bot:
                df_ohlcv = df_ohlcv.sort_index()

            df_market_index = pd.read_sql_query(f'SELECT * FROM "{config.MARKET_INDEX_TABLE}"', con,
                                                index_col='timestamp', parse_dates=['timestamp'])

        with sqlite3.connect(config.FNG_DB_PATH) as con:
            df_fng = pd.read_sql_query(f'SELECT * FROM "{config.FNG_TABLE}"', con, index_col='timestamp',
                                       parse_dates=['timestamp'])

        with sqlite3.connect(config.MACRO_DB_PATH) as con:
            df_macro = pd.read_sql_query(f'SELECT * FROM "{config.MACRO_TABLE}"', con, index_col='index',
                                         parse_dates=['index'])
            df_macro.index.name = 'timestamp'  # ì¸ë±ìŠ¤ ì´ë¦„ í†µì¼

        logger.info(
            f" -> ê° DBì—ì„œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: OHLCV({len(df_ohlcv)}), ì‹œì¥ì§€ìˆ˜({len(df_market_index)}), F&G({len(df_fng)}), ê±°ì‹œê²½ì œ({len(df_macro)})")

        # 2. ì‹œê°„ëŒ€ ì •ë³´ í†µì¼ (ë°ì´í„° ë³‘í•© ì „ í•„ìˆ˜)
        for df in [df_ohlcv, df_fng, df_market_index, df_macro]:
            if not df.empty and df.index.tz:
                df.index = df.index.tz_localize(None)

        # 3. ë°ì´í„° ë³‘í•© (OHLCVë¥¼ ê¸°ì¤€ìœ¼ë¡œ)
        df_merged = df_ohlcv
        if not df_market_index.empty:
            df_merged = df_merged.join(df_market_index[['market_index_value']], how='left')
        if not df_fng.empty:
            df_merged = df_merged.join(df_fng[['fng_value']], how='left')
        if not df_macro.empty:
            df_merged = df_merged.join(df_macro, how='left')

        # 4. ë°ì´í„° í›„ì²˜ë¦¬
        # ffill(): ëˆ„ë½ëœ ê°’(NaN)ì„ ë°”ë¡œ ì´ì „ ê°’ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤. (ì£¼ë§ ë“± ë°ì´í„°ê°€ ì—†ëŠ” ë‚  ì²˜ë¦¬)
        df_merged.ffill(inplace=True)
        # í•„ìˆ˜ ì»¬ëŸ¼ì— ë°ì´í„°ê°€ ì—†ëŠ” í–‰ì€ ì œê±°í•©ë‹ˆë‹¤.
        df_merged.dropna(subset=['close'], inplace=True)

        logger.info(f"âœ… ë°ì´í„° ë³‘í•© ë° ì „ì²˜ë¦¬ ì™„ë£Œ. ìµœì¢… ë°ì´í„°: {len(df_merged)} í–‰")
        return df_merged

    except Exception as e:
        logger.error(f"ë°ì´í„° ë¡œë“œ ë˜ëŠ” ë³‘í•© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return pd.DataFrame()

def load_all_ohlcv_data(tickers: list, interval: str) -> dict:
    """
    ì§€ì •ëœ ëª¨ë“  í‹°ì»¤ì— ëŒ€í•œ OHLCV ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    """
    all_data = {}
    for ticker in tickers:
        try:
            # ê¸°ì¡´ load_prepared_data í•¨ìˆ˜ë¥¼ ì¬í™œìš©í•©ë‹ˆë‹¤.
            df = load_prepared_data(ticker, interval)
            if not df.empty:
                all_data[ticker] = df
        except Exception as e:
            print(f"{ticker} ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")  # ë¡œê¹…ìœ¼ë¡œ ëŒ€ì²´ ê¶Œì¥
    return all_data